/**
 * NakamaBot - Commande /chat avec M√âMOIRE CONTEXTUELLE et recherche GRATUITE
 * + D√©tection commandes 100% IA (pas de mots-cl√©s)
 * + Recherche contextuelle bas√©e sur l'historique de conversation
 * + Support Markdown vers Unicode stylis√© pour Facebook Messenger
 * + Syst√®me de troncature synchronis√©
 * @param {string} senderId - ID de l'utilisateur
 * @param {string} args - Message de conversation
 * @param {object} ctx - Contexte partag√© du bot 
 */

const { GoogleGenerativeAI } = require("@google/generative-ai");
const axios = require("axios");
const cheerio = require("cheerio");

// ========================================
// üîë CONFIGURATION APIs
// ========================================

const GEMINI_API_KEYS = process.env.GEMINI_API_KEY ? process.env.GEMINI_API_KEY.split(',').map(key => key.trim()) : [];

// üÜï RECHERCHE GRATUITE
const SEARCH_CONFIG = {
    duckduckgo: {
        enabled: true,
        baseUrl: 'https://html.duckduckgo.com/html/',
        timeout: 8000,
        maxResults: 5
    },
    wikipedia: {
        enabled: true,
        baseUrl: 'https://fr.wikipedia.org/api/rest_v1',
        timeout: 6000,
        maxResults: 3
    },
    webScraping: {
        enabled: true,
        timeout: 10000,
        userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
};

const SEARCH_RETRY_DELAY = 2000;
const SEARCH_GLOBAL_COOLDOWN = 3000;

// √âtat global
let currentGeminiKeyIndex = 0;
const failedKeys = new Set();
const activeRequests = new Map();
const recentMessages = new Map();
const searchCache = new Map();
const CACHE_TTL = 3600000; // 1 heure

// üÜï CACHE DE CONTEXTE CONVERSATIONNEL (pour analyse contextuelle)
const conversationContext = new Map(); // senderId -> { lastTopic, entities, intent }

// ========================================
// üé® FONCTIONS MARKDOWN ‚Üí UNICODE
// ========================================

const UNICODE_MAPPINGS = {
    bold: {
        'a': 'ùóÆ', 'b': 'ùóØ', 'c': 'ùó∞', 'd': 'ùó±', 'e': 'ùó≤', 'f': 'ùó≥', 'g': 'ùó¥', 'h': 'ùóµ', 'i': 'ùó∂', 'j': 'ùó∑', 'k': 'ùó∏', 'l': 'ùóπ', 'm': 'ùó∫',
        'n': 'ùóª', 'o': 'ùóº', 'p': 'ùóΩ', 'q': 'ùóæ', 'r': 'ùóø', 's': 'ùòÄ', 't': 'ùòÅ', 'u': 'ùòÇ', 'v': 'ùòÉ', 'w': 'ùòÑ', 'x': 'ùòÖ', 'y': 'ùòÜ', 'z': 'ùòá',
        'A': 'ùóî', 'B': 'ùóï', 'C': 'ùóñ', 'D': 'ùóó', 'E': 'ùóò', 'F': 'ùóô', 'G': 'ùóö', 'H': 'ùóõ', 'I': 'ùóú', 'J': 'ùóù', 'K': 'ùóû', 'L': 'ùóü', 'M': 'ùó†',
        'N': 'ùó°', 'O': 'ùó¢', 'P': 'ùó£', 'Q': 'ùó§', 'R': 'ùó•', 'S': 'ùó¶', 'T': 'ùóß', 'U': 'ùó®', 'V': 'ùó©', 'W': 'ùó™', 'X': 'ùó´', 'Y': 'ùó¨', 'Z': 'ùó≠',
        '0': 'ùü¨', '1': 'ùü≠', '2': 'ùüÆ', '3': 'ùüØ', '4': 'ùü∞', '5': 'ùü±', '6': 'ùü≤', '7': 'ùü≥', '8': 'ùü¥', '9': 'ùüµ'
    }
};

function toBold(str) {
    return str.split('').map(char => UNICODE_MAPPINGS.bold[char] || char).join('');
}

function toUnderline(str) {
    return str.split('').map(char => char + '\u0332').join('');
}

function toStrikethrough(str) {
    return str.split('').map(char => char + '\u0336').join('');
}

function parseMarkdown(text) {
    if (!text || typeof text !== 'string') return text;
    
    let parsed = text;
    parsed = parsed.replace(/^###\s+(.+)$/gm, (match, title) => `üîπ ${toBold(title.trim())}`);
    parsed = parsed.replace(/\*\*([^*]+)\*\*/g, (match, content) => toBold(content));
    parsed = parsed.replace(/__([^_]+)__/g, (match, content) => toUnderline(content));
    parsed = parsed.replace(/~~([^~]+)~~/g, (match, content) => toStrikethrough(content));
    parsed = parsed.replace(/^[\s]*[-*]\s+(.+)$/gm, (match, content) => `‚Ä¢ ${content.trim()}`);
    
    return parsed;
}

// ========================================
// üîë GESTION ROTATION CL√âS GEMINI
// ========================================

function getNextGeminiKey() {
    if (GEMINI_API_KEYS.length === 0) {
        throw new Error('Aucune cl√© Gemini configur√©e');
    }
    
    if (failedKeys.size >= GEMINI_API_KEYS.length) {
        failedKeys.clear();
        currentGeminiKeyIndex = 0;
    }
    
    let attempts = 0;
    while (attempts < GEMINI_API_KEYS.length) {
        const key = GEMINI_API_KEYS[currentGeminiKeyIndex];
        currentGeminiKeyIndex = (currentGeminiKeyIndex + 1) % GEMINI_API_KEYS.length;
        
        if (!failedKeys.has(key)) return key;
        attempts++;
    }
    
    failedKeys.clear();
    currentGeminiKeyIndex = 0;
    return GEMINI_API_KEYS[0];
}

function markKeyAsFailed(apiKey) {
    failedKeys.add(apiKey);
}

async function callGeminiWithRotation(prompt, maxRetries = GEMINI_API_KEYS.length) {
    let lastError = null;
    
    for (let attempt = 0; attempt < maxRetries; attempt++) {
        try {
            const apiKey = getNextGeminiKey();
            const genAI = new GoogleGenerativeAI(apiKey);
            const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash-exp" });
            
            const result = await model.generateContent(prompt);
            const response = result.response.text();
            
            if (response && response.trim()) {
                failedKeys.delete(apiKey);
                return response;
            }
            
            throw new Error('R√©ponse Gemini vide');
            
        } catch (error) {
            lastError = error;
            
            if (error.message.includes('API_KEY') || error.message.includes('quota') || error.message.includes('limit')) {
                const currentKey = GEMINI_API_KEYS[(currentGeminiKeyIndex - 1 + GEMINI_API_KEYS.length) % GEMINI_API_KEYS.length];
                markKeyAsFailed(currentKey);
            }
            
            if (attempt === maxRetries - 1) throw lastError;
        }
    }
    
    throw lastError || new Error('Toutes les cl√©s Gemini ont √©chou√©');
}

// ========================================
// üÜï RECHERCHE GRATUITE - 3 M√âTHODES
// ========================================

async function searchDuckDuckGo(query, log) {
    const cacheKey = `ddg_${query.toLowerCase()}`;
    const cached = searchCache.get(cacheKey);
    
    if (cached && (Date.now() - cached.timestamp < CACHE_TTL)) {
        log.info(`üíæ Cache DuckDuckGo hit pour: ${query}`);
        return cached.results;
    }
    
    try {
        const response = await axios.post(
            SEARCH_CONFIG.duckduckgo.baseUrl,
            `q=${encodeURIComponent(query)}&kl=fr-fr`,
            {
                headers: {
                    'Content-Type': 'application/x-www-form-urlencoded',
                    'User-Agent': SEARCH_CONFIG.webScraping.userAgent
                },
                timeout: SEARCH_CONFIG.duckduckgo.timeout
            }
        );
        
        const $ = cheerio.load(response.data);
        const results = [];
        
        $('.result').slice(0, SEARCH_CONFIG.duckduckgo.maxResults).each((i, elem) => {
            const titleElem = $(elem).find('.result__title');
            const snippetElem = $(elem).find('.result__snippet');
            const linkElem = $(elem).find('.result__url');
            
            const title = titleElem.text().trim();
            const snippet = snippetElem.text().trim();
            const link = linkElem.attr('href') || titleElem.find('a').attr('href');
            
            if (title && snippet) {
                results.push({
                    title,
                    description: snippet,
                    link: link || 'N/A',
                    source: 'duckduckgo'
                });
            }
        });
        
        if (results.length > 0) {
            searchCache.set(cacheKey, { results, timestamp: Date.now() });
            log.info(`ü¶Ü DuckDuckGo: ${results.length} r√©sultats pour "${query}"`);
            return results;
        }
        
        return [];
        
    } catch (error) {
        log.warning(`‚ö†Ô∏è DuckDuckGo √©chec: ${error.message}`);
        return [];
    }
}

async function searchWikipedia(query, log) {
    const cacheKey = `wiki_${query.toLowerCase()}`;
    const cached = searchCache.get(cacheKey);
    
    if (cached && (Date.now() - cached.timestamp < CACHE_TTL)) {
        log.info(`üíæ Cache Wikipedia hit pour: ${query}`);
        return cached.results;
    }
    
    try {
        const searchUrl = `${SEARCH_CONFIG.wikipedia.baseUrl}/page/search/${encodeURIComponent(query)}`;
        const searchResponse = await axios.get(searchUrl, {
            params: { limit: SEARCH_CONFIG.wikipedia.maxResults },
            timeout: SEARCH_CONFIG.wikipedia.timeout
        });
        
        if (!searchResponse.data.pages || searchResponse.data.pages.length === 0) {
            return [];
        }
        
        const results = [];
        
        for (const page of searchResponse.data.pages.slice(0, 2)) {
            try {
                const summaryUrl = `${SEARCH_CONFIG.wikipedia.baseUrl}/page/summary/${encodeURIComponent(page.title)}`;
                const summaryResponse = await axios.get(summaryUrl, {
                    timeout: SEARCH_CONFIG.wikipedia.timeout
                });
                
                const summary = summaryResponse.data;
                results.push({
                    title: summary.title,
                    description: summary.extract,
                    link: summary.content_urls?.desktop?.page || 'https://fr.wikipedia.org',
                    source: 'wikipedia'
                });
            } catch (error) {
                // Ignorer erreurs individuelles
            }
        }
        
        if (results.length > 0) {
            searchCache.set(cacheKey, { results, timestamp: Date.now() });
            log.info(`üìö Wikipedia: ${results.length} r√©sultats pour "${query}"`);
            return results;
        }
        
        return [];
        
    } catch (error) {
        log.warning(`‚ö†Ô∏è Wikipedia √©chec: ${error.message}`);
        return [];
    }
}

async function searchWebScraping(query, log) {
    const cacheKey = `scrape_${query.toLowerCase()}`;
    const cached = searchCache.get(cacheKey);
    
    if (cached && (Date.now() - cached.timestamp < CACHE_TTL / 2)) {
        log.info(`üíæ Cache Scraping hit pour: ${query}`);
        return cached.results;
    }
    
    try {
        const sources = [
            `https://news.google.com/search?q=${encodeURIComponent(query)}&hl=fr&gl=FR&ceid=FR:fr`,
            `https://search.yahoo.com/search?p=${encodeURIComponent(query)}&fr=yfp-t`
        ];
        
        const results = [];
        
        for (const url of sources) {
            try {
                const response = await axios.get(url, {
                    headers: { 'User-Agent': SEARCH_CONFIG.webScraping.userAgent },
                    timeout: SEARCH_CONFIG.webScraping.timeout
                });
                
                const $ = cheerio.load(response.data);
                
                if (url.includes('news.google.com')) {
                    $('article').slice(0, 3).each((i, elem) => {
                        const title = $(elem).find('a').first().text().trim();
                        const snippet = $(elem).find('p').text().trim();
                        
                        if (title && snippet) {
                            results.push({
                                title,
                                description: snippet,
                                link: 'https://news.google.com',
                                source: 'google_news'
                            });
                        }
                    });
                }
                
                if (url.includes('yahoo.com')) {
                    $('.dd.algo').slice(0, 2).each((i, elem) => {
                        const title = $(elem).find('h3').text().trim();
                        const snippet = $(elem).find('.compText').text().trim();
                        
                        if (title && snippet) {
                            results.push({
                                title,
                                description: snippet,
                                link: 'N/A',
                                source: 'yahoo'
                            });
                        }
                    });
                }
                
                if (results.length >= 3) break;
                
            } catch (error) {
                // Continue
            }
        }
        
        if (results.length > 0) {
            searchCache.set(cacheKey, { results, timestamp: Date.now() });
            log.info(`üåê Web Scraping: ${results.length} r√©sultats pour "${query}"`);
            return results;
        }
        
        return [];
        
    } catch (error) {
        log.warning(`‚ö†Ô∏è Web Scraping √©chec: ${error.message}`);
        return [];
    }
}

async function performIntelligentSearch(query, ctx) {
    const { log } = ctx;
    
    try {
        if (SEARCH_CONFIG.duckduckgo.enabled) {
            const ddgResults = await searchDuckDuckGo(query, log);
            if (ddgResults.length > 0) return ddgResults;
        }
        
        await new Promise(resolve => setTimeout(resolve, 500));
        
        if (SEARCH_CONFIG.wikipedia.enabled) {
            const wikiResults = await searchWikipedia(query, log);
            if (wikiResults.length > 0) return wikiResults;
        }
        
        await new Promise(resolve => setTimeout(resolve, 500));
        
        if (SEARCH_CONFIG.webScraping.enabled) {
            const scrapeResults = await searchWebScraping(query, log);
            if (scrapeResults.length > 0) return scrapeResults;
        }
        
        log.warning(`‚ö†Ô∏è Aucun r√©sultat trouv√© pour: ${query}`);
        return [];
        
    } catch (error) {
        log.error(`‚ùå Erreur recherche combin√©e: ${error.message}`);
        return [];
    }
}

// ========================================
// üß† ANALYSE CONTEXTUELLE DE CONVERSATION
// ========================================

/**
 * üÜï EXTRACTION DU CONTEXTE CONVERSATIONNEL
 * Analyse l'historique pour comprendre le sujet actuel et les entit√©s mentionn√©es
 */
async function analyzeConversationContext(senderId, currentMessage, conversationHistory, ctx) {
    const { log } = ctx;
    
    try {
        // Construire l'historique des 5 derniers messages
        const recentHistory = conversationHistory.slice(-5).map(msg => 
            `${msg.role === 'user' ? 'Utilisateur' : 'Bot'}: ${msg.content}`
        ).join('\n');
        
        const contextPrompt = `Tu es un analyseur de contexte conversationnel ultra-pr√©cis.

HISTORIQUE R√âCENT:
${recentHistory}

MESSAGE ACTUEL: "${currentMessage}"

ANALYSE LE CONTEXTE ET EXTRAIS:
1. **Sujet principal** de la conversation (ex: "Cameroun football", "m√©t√©o Paris", "histoire France")
2. **Entit√©s cl√©s** mentionn√©es (pays, personnes, lieux, √©v√©nements, √©quipes sportives)
3. **Intention** du message actuel (nouvelle_question, continuation, clarification, changement_sujet)
4. **R√©f√©rence contextuelle** : le message actuel fait-il r√©f√©rence √† quelque chose mentionn√© avant ? (ex: "leur rang" ‚Üí r√©f√©rence √† une √©quipe mentionn√©e)

EXEMPLES:
- Historique: "Le Cameroun est quanti√®me ?" / Actuel: "je veux leur rang dans leur poule"
  ‚Üí Sujet: "Cameroun football classement", Entit√©s: ["Cameroun", "poule"], Intention: "continuation", R√©f√©rence: "Cameroun (mentionn√© pr√©c√©demment)"

- Historique: "Qui est Messi ?" / Actuel: "combien de buts il a marqu√© ?"
  ‚Üí Sujet: "Messi statistiques", Entit√©s: ["Messi", "buts"], Intention: "continuation", R√©f√©rence: "Messi (mentionn√© pr√©c√©demment)"

R√©ponds UNIQUEMENT avec ce JSON:
{
  "mainTopic": "sujet_principal_complet",
  "entities": ["entit√©1", "entit√©2"],
  "intent": "nouvelle_question|continuation|clarification|changement_sujet",
  "contextualReference": "description_de_la_r√©f√©rence_ou_null",
  "enrichedQuery": "requ√™te_de_recherche_enrichie_avec_contexte"
}`;

        const response = await callGeminiWithRotation(contextPrompt);
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        
        if (jsonMatch) {
            const context = JSON.parse(jsonMatch[0]);
            
            // Sauvegarder le contexte pour cet utilisateur
            conversationContext.set(senderId, {
                lastTopic: context.mainTopic,
                entities: context.entities,
                intent: context.intent,
                timestamp: Date.now()
            });
            
            log.info(`üß† Contexte analys√©: ${context.intent} | Sujet: ${context.mainTopic}`);
            if (context.contextualReference) {
                log.info(`üîó R√©f√©rence contextuelle d√©tect√©e: ${context.contextualReference}`);
            }
            
            return context;
        }
        
        throw new Error('Format JSON invalide');
        
    } catch (error) {
        log.warning(`‚ö†Ô∏è Erreur analyse contexte: ${error.message}`);
        
        // Fallback: retourner le message brut
        return {
            mainTopic: currentMessage,
            entities: [],
            intent: 'nouvelle_question',
            contextualReference: null,
            enrichedQuery: currentMessage
        };
    }
}

// ========================================
// ü§ñ D√âCISION IA POUR RECHERCHE (AVEC CONTEXTE)
// ========================================

async function decideSearchNecessity(userMessage, senderId, conversationHistory, ctx) {
    const { log } = ctx;
    
    try {
        // üÜï D'ABORD: Analyser le contexte conversationnel
        const contextAnalysis = await analyzeConversationContext(senderId, userMessage, conversationHistory, ctx);
        
        // Construire l'historique pour la d√©cision
        const recentHistory = conversationHistory.slice(-5).map(msg => 
            `${msg.role === 'user' ? 'Utilisateur' : 'Bot'}: ${msg.content}`
        ).join('\n');
        
        const decisionPrompt = `Tu es un syst√®me de d√©cision intelligent pour un chatbot avec M√âMOIRE CONTEXTUELLE.

HISTORIQUE R√âCENT:
${recentHistory}

MESSAGE ACTUEL: "${userMessage}"

ANALYSE CONTEXTUELLE:
- Sujet principal: ${contextAnalysis.mainTopic}
- Entit√©s cl√©s: ${contextAnalysis.entities.join(', ')}
- Intention: ${contextAnalysis.intent}
- R√©f√©rence: ${contextAnalysis.contextualReference || 'aucune'}

R√àGLES DE D√âCISION:

‚úÖ RECHERCHE N√âCESSAIRE si:
- Informations r√©centes/actuelles (actualit√©s, √©v√©nements 2025-2026)
- Donn√©es factuelles sp√©cifiques (classements sportifs, prix, statistiques, dates)
- Questions de continuation n√©cessitant des donn√©es externes (ex: "leur rang" apr√®s avoir parl√© d'une √©quipe)
- Informations locales/g√©ographiques
- Questions sur personnes publiques r√©centes
- M√©t√©o, cours, r√©sultats sportifs

‚ùå PAS DE RECHERCHE si:
- Conversations g√©n√©rales/philosophiques
- Conseils/opinions personnelles
- Questions sur le bot lui-m√™me
- Cr√©ativit√© (histoires, po√®mes)
- Explications de concepts g√©n√©raux que l'IA conna√Æt
- Questions existantes dans la base de connaissances

üîç REQU√äTE ENRICHIE:
Si recherche n√©cessaire ET que c'est une continuation contextuelle, ENRICHIS la requ√™te avec les entit√©s pr√©c√©dentes.
Exemple: Message actuel "leur rang dans leur poule" + Contexte "Cameroun football" ‚Üí Requ√™te: "Cameroun classement poule football 2025"

R√©ponds UNIQUEMENT avec ce JSON:
{
  "needsExternalSearch": true/false,
  "confidence": 0.0-1.0,
  "reason": "explication_d√©taill√©e",
  "searchQuery": "requ√™te_optimis√©e_avec_contexte",
  "usesConversationMemory": true/false
}`;

        const response = await callGeminiWithRotation(decisionPrompt);
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        
        if (jsonMatch) {
            const decision = JSON.parse(jsonMatch[0]);
            
            log.info(`ü§ñ D√©cision recherche: ${decision.needsExternalSearch ? 'OUI' : 'NON'} (${decision.confidence})`);
            log.info(`üìù Raison: ${decision.reason}`);
            
            if (decision.usesConversationMemory) {
                log.info(`üß† Utilise la m√©moire conversationnelle pour enrichir la recherche`);
            }
            
            return decision;
        }
        
        throw new Error('Format invalide');
        
    } catch (error) {
        log.warning(`‚ö†Ô∏è Erreur d√©cision recherche: ${error.message}`);
        
        // Fallback simple
        return {
            needsExternalSearch: false,
            confidence: 0.5,
            reason: 'fallback',
            searchQuery: userMessage,
            usesConversationMemory: false
        };
    }
}

// ========================================
// üéØ D√âTECTION COMMANDES 100% IA (PAS DE MOTS-CL√âS)
// ========================================

const VALID_COMMANDS = [
    'help', 'image', 'vision', 'anime', 'music', 
    'clan', 'rank', 'contact', 'weather'
];

async function detectIntelligentCommands(message, conversationHistory, ctx) {
    const { log } = ctx;
    
    try {
        const commandsList = VALID_COMMANDS.map(cmd => `/${cmd}`).join(', ');
        
        // Construire l'historique pour contexte
        const recentHistory = conversationHistory.slice(-3).map(msg => 
            `${msg.role === 'user' ? 'Utilisateur' : 'Bot'}: ${msg.content}`
        ).join('\n');
        
        const detectionPrompt = `Tu es un syst√®me de d√©tection de commandes ULTRA-INTELLIGENT avec M√âMOIRE CONTEXTUELLE.

COMMANDES DISPONIBLES: ${commandsList}

HISTORIQUE R√âCENT:
${recentHistory}

MESSAGE ACTUEL: "${message}"

ANALYSE INTENTION PROFONDE:

üéØ VRAIS INTENTIONS (confidence 0.85-1.0):
‚úÖ help: Demande d'aide, guide, liste des fonctionnalit√©s
‚úÖ image: Demande explicite de cr√©ation/g√©n√©ration d'image, dessin, illustration
‚úÖ vision: Demande d'analyse d'une image, description visuelle (suppose qu'une image est envoy√©e)
‚úÖ anime: Demande de transformation en style anime/manga d'une image
‚úÖ music: Demande de recherche de musique sur YouTube, jouer une chanson
‚úÖ clan: Demande li√©e aux clans du bot (rejoindre, cr√©er, bataille)
‚úÖ rank: Demande de statistiques personnelles, niveau, progression dans le bot
‚úÖ contact: Demande de contacter les administrateurs, signaler un probl√®me
‚úÖ weather: Demande de m√©t√©o, pr√©visions, temp√©rature

‚ùå FAUSSES D√âTECTIONS (confidence 0.0-0.4):
- Questions g√©n√©rales mentionnant un mot-cl√©: "quel chanteur a chant√© cette musique" ‚â† /music
- Conversations normales: "j'aime la musique", "le temps passe", "aide mon ami"
- Descriptions: "cette image est belle", "il fait chaud", "niveau d√©butant"
- Questions informatives: "c'est quoi la m√©t√©o", "les clans vikings"

R√àGLES STRICTES:
1. L'utilisateur DOIT vouloir UTILISER une fonctionnalit√© du bot
2. Il DOIT y avoir une DEMANDE D'ACTION claire dirig√©e vers le bot
3. Tenir compte du CONTEXTE conversationnel (si on vient de parler de football et il dit "leur classement", ce n'est PAS une commande)
4. Ne d√©tecte une commande QUE si confidence >= 0.85

R√©ponds UNIQUEMENT avec ce JSON:
{
  "isCommand": true/false,
  "command": "nom_commande_ou_null",
  "confidence": 0.0-1.0,
  "extractedArgs": "arguments_extraits_ou_message_complet",
  "reason": "explication_d√©taill√©e",
  "conversationContext": "analyse_du_contexte"
}`;

        const response = await callGeminiWithRotation(detectionPrompt);
        const jsonMatch = response.match(/\{[\s\S]*\}/);
        
        if (jsonMatch) {
            const aiDetection = JSON.parse(jsonMatch[0]);
            
            // Validation stricte: seuil √©lev√© de 0.85
            const isValid = aiDetection.isCommand && 
                          VALID_COMMANDS.includes(aiDetection.command) && 
                          aiDetection.confidence >= 0.85;
            
            if (isValid) {
                log.info(`üéØ Commande IA d√©tect√©e: /${aiDetection.command} (${aiDetection.confidence})`);
                log.info(`üìù Raison: ${aiDetection.reason}`);
                log.info(`üß† Contexte: ${aiDetection.conversationContext}`);
                
                return {
                    shouldExecute: true,
                    command: aiDetection.command,
                    args: aiDetection.extractedArgs,
                    confidence: aiDetection.confidence,
                    method: 'ai_100percent'
                };
            } else if (aiDetection.confidence > 0.4 && aiDetection.confidence < 0.85) {
                log.info(`üö´ Commande rejet√©e (confidence ${aiDetection.confidence}): ${aiDetection.reason}`);
            }
        }
        
        return { shouldExecute: false };
        
    } catch (error) {
        log.warning(`‚ö†Ô∏è Erreur d√©tection IA commandes: ${error.message}`);
        return { shouldExecute: false };
    }
}

// ========================================
// üé≠ G√âN√âRATION R√âPONSE AVEC CONTEXTE
// ========================================

async function generateNaturalResponseWithContext(originalQuery, searchResults, conversationContext, ctx) {
    const { log, callMistralAPI } = ctx;
    
    const now = new Date();
    const dateTime = now.toLocaleString('fr-FR', { 
        weekday: 'long', 
        year: 'numeric', 
        month: 'long', 
        day: 'numeric', 
        hour: '2-digit', 
        minute: '2-digit',
        timeZone: 'Europe/Paris'
    });
    
    try {
        const resultsText = searchResults.map((result, index) => 
            `${index + 1}. ${result.title}: ${result.description}`
        ).join('\n\n');
        
        let conversationHistory = "";
        if (conversationContext && conversationContext.length > 0) {
            conversationHistory = conversationContext.map(msg => 
                `${msg.role === 'user' ? 'Utilisateur' : 'NakamaBot'}: ${msg.content}`
            ).join('\n') + '\n';
        }
        
        const contextualPrompt = `Tu es NakamaBot, une IA conversationnelle empathique avec M√âMOIRE CONTEXTUELLE.

CONTEXTE TEMPOREL: ${dateTime}

HISTORIQUE COMPLET DE CONVERSATION:
${conversationHistory || "D√©but de conversation"}

QUESTION ACTUELLE: "${originalQuery}"

INFORMATIONS TROUV√âES VIA RECHERCHE:
${resultsText}

INSTRUCTIONS CRITIQUES:
- Tu as une M√âMOIRE COMPL√àTE de toute la conversation ci-dessus
- Si l'utilisateur fait r√©f√©rence √† quelque chose mentionn√© avant (ex: "leur rang", "combien de buts", "son √¢ge"), tu SAIS de quoi il parle gr√¢ce √† l'historique
- R√©ponds en tenant compte de TOUT le contexte pr√©c√©dent
- Ton conversationnel et amical avec quelques emojis
- Maximum 1999 caract√®res
- NE MENTIONNE JAMAIS que tu as fait une recherche
- NE DIS JAMAIS "d'apr√®s mes recherches", "selon les sources", "j'ai trouv√©"
- R√©ponds naturellement comme si tu connaissais d√©j√† ces informations
- Si c'est une question de suivi (ex: "leur rang" apr√®s avoir parl√© du Cameroun), int√®gre naturellement le contexte
- Utilise Markdown simple (**gras**, ### titres, listes)
- PAS d'italique (*texte*)

EXEMPLE DE R√âPONSE CONTEXTUELLE:
Historique: "Le Cameroun est quanti√®me ?" ‚Üí Bot: "Le Cameroun est 56√®me..."
Actuel: "leur rang dans leur poule" ‚Üí Bot: "Le Cameroun est 2√®me de sa poule avec..."

R√âPONSE NATURELLE EN CONTINUIT√â:`;

        const response = await callGeminiWithRotation(contextualPrompt);
        
        if (response && response.trim()) {
            log.info(`üé≠ R√©ponse contextuelle Gemini g√©n√©r√©e`);
            return response;
        }
        
        throw new Error('R√©ponse Gemini vide');
        
    } catch (geminiError) {
        log.warning(`‚ö†Ô∏è Gemini √©chec: ${geminiError.message}`);
        
        try {
            const messages = [{
                role: "system",
                content: `Tu es NakamaBot avec M√âMOIRE COMPL√àTE. Tu connais tout l'historique. R√©ponds naturellement en tenant compte du contexte. Ne mentionne JAMAIS de recherches. Markdown simple OK.

Historique complet:
${conversationContext ? conversationContext.map(msg => `${msg.role === 'user' ? 'Utilisateur' : 'NakamaBot'}: ${msg.content}`).join('\n') : "D√©but"}`
            }, {
                role: "user", 
                content: `Question actuelle: "${originalQuery}"

Informations trouv√©es:
${searchResults.map(r => `${r.title}: ${r.description}`).join('\n')}

R√©ponds naturellement en continuit√© de la conversation, comme si tu connaissais d√©j√† ces infos (max 2000 chars):`
            }];
            
            const mistralResponse = await callMistralAPI(messages, 2000, 0.7);
            
            if (mistralResponse) {
                log.info(`üîÑ R√©ponse contextuelle Mistral g√©n√©r√©e`);
                return mistralResponse;
            }
            
            throw new Error('Mistral √©chec aussi');
            
        } catch (mistralError) {
            log.error(`‚ùå Erreur totale: ${mistralError.message}`);
            
            const topResult = searchResults[0];
            if (topResult) {
                return `D'apr√®s ce que je sais, ${topResult.description} üí°`;
            }
            
            return null;
        }
    }
}

// ========================================
// üí¨ CONVERSATION UNIFI√âE AVEC RECHERCHE INT√âGR√âE
// ========================================

async function handleConversationWithFallback(senderId, args, ctx, searchResults = null) {
    const { addToMemory, getMemoryContext, callMistralAPI, log, 
            splitMessageIntoChunks, truncatedMessages } = ctx;
    
    const context = getMemoryContext(String(senderId)).slice(-8);
    const messageCount = context.filter(msg => msg.role === 'user').length;
    
    const now = new Date();
    const dateTime = now.toLocaleString('fr-FR', { 
        weekday: 'long', 
        year: 'numeric', 
        month: 'long', 
        day: 'numeric', 
        hour: '2-digit', 
        minute: '2-digit',
        timeZone: 'Europe/Paris'
    });
    
    let conversationHistory = "";
    if (context.length > 0) {
        conversationHistory = context.map(msg => 
            `${msg.role === 'user' ? 'Utilisateur' : 'Assistant'}: ${msg.content}`
        ).join('\n') + '\n';
    }
    
    // üÜï INJECTION DYNAMIQUE DES R√âSULTATS DE RECHERCHE
    let searchContext = "";
    if (searchResults && searchResults.length > 0) {
        searchContext = `\n\nüîç INFORMATIONS R√âCENTES DISPONIBLES (utilise-les naturellement si pertinent):
${searchResults.map((result, index) => 
    `${index + 1}. ${result.title}: ${result.description}`
).join('\n\n')}

‚ö†Ô∏è IMPORTANT: Ne mentionne JAMAIS que tu as fait une recherche. Int√®gre ces informations naturellement dans ta r√©ponse comme si tu les connaissais d√©j√†.`;
    }
    
    const systemPrompt = `Tu es NakamaBot, une IA conversationnelle avanc√©e avec M√âMOIRE CONTEXTUELLE cr√©√©e par Durand et C√©cile.

CONTEXTE TEMPOREL: ${dateTime}

INTELLIGENCE & PERSONNALIT√â:
- Empathique, cr√©ative et intuitive avec M√âMOIRE COMPL√àTE de la conversation
- Tu te souviens de TOUT ce qui a √©t√© dit dans l'historique ci-dessous
- Si l'utilisateur fait r√©f√©rence √† quelque chose mentionn√© avant, tu SAIS de quoi il parle
- P√©dagogue naturelle qui explique clairement
- Adaptable selon contexte

CAPACIT√âS:
üé® Cr√©ation d'images ("dessine-moi...")
üëÅÔ∏è Analyse d'images ("regarde cette image")
üå∏ Transformation anime ("style manga")
üéµ Recherche musicale YouTube ("joue...")
üõ°Ô∏è Syst√®me clans et batailles ("clan")
üìä Progression et niveau ("mon niveau")
üìû Contact admin ("contacter admin")
üîç Recherche intelligente automatique avec m√©moire contextuelle
üÜò Guide complet ("aide")

DIRECTIVES:
- Langue selon utilisateur
- Maximum 1999 caract√®res
- Quelques emojis avec parcimonie
- √âvite r√©p√©titions
- ${messageCount >= 5 ? 'Sugg√®re /help si pertinent' : ''}
- Pour questions techniques: "Demande √† Durand ou C√©cile !"
- Recommande /contact pour probl√®mes graves
- Markdown simple OK (**gras**, ### titres, listes)
- PAS d'italique
- UTILISE ta M√âMOIRE: si l'utilisateur dit "et lui ?", "combien ?", "leur classement ?", tu sais de qui/quoi il parle gr√¢ce √† l'historique
- Si des informations r√©centes sont disponibles ci-dessous, int√®gre-les naturellement sans jamais dire "j'ai trouv√©" ou "d'apr√®s mes recherches"

HISTORIQUE COMPLET:
${conversationHistory ? conversationHistory : 'D√©but de conversation'}
${searchContext}

Utilisateur: ${args}`;

    const senderIdStr = String(senderId);

    try {
        const geminiResponse = await callGeminiWithRotation(systemPrompt);
        
        if (geminiResponse && geminiResponse.trim()) {
            const styledResponse = parseMarkdown(geminiResponse);
            
            if (styledResponse.length > 2000) {
                const chunks = splitMessageIntoChunks(styledResponse, 2000);
                const firstChunk = chunks[0];
                
                if (chunks.length > 1) {
                    truncatedMessages.set(senderIdStr, {
                        fullMessage: styledResponse,
                        lastSentPart: firstChunk,
                        timestamp: new Date().toISOString()
                    });
                    
                    const truncatedResponse = firstChunk + "\n\nüìù *Tape \"continue\" pour la suite...*";
                    addToMemory(senderIdStr, 'user', args);
                    addToMemory(senderIdStr, 'assistant', truncatedResponse);
                    log.info(`üíé Gemini avec troncature${searchResults ? ' (+ recherche int√©gr√©e)' : ''}`);
                    return truncatedResponse;
                }
            }
            
            addToMemory(senderIdStr, 'user', args);
            addToMemory(senderIdStr, 'assistant', styledResponse);
            log.info(`üíé Gemini r√©ponse normale${searchResults ? ' (+ recherche int√©gr√©e)' : ''}`);
            return styledResponse;
        }
        
        throw new Error('R√©ponse Gemini vide');
        
    } catch (geminiError) {
        log.warning(`‚ö†Ô∏è Gemini √©chec: ${geminiError.message}`);
        
        try {
            const messages = [{ role: "system", content: systemPrompt }];
            messages.push(...context);
            messages.push({ role: "user", content: args });
            
            const mistralResponse = await callMistralAPI(messages, 2000, 0.75);
            
            if (mistralResponse) {
                const styledResponse = parseMarkdown(mistralResponse);
                
                if (styledResponse.length > 2000) {
                    const chunks = splitMessageIntoChunks(styledResponse, 2000);
                    const firstChunk = chunks[0];
                    
                    if (chunks.length > 1) {
                        truncatedMessages.set(senderIdStr, {
                            fullMessage: styledResponse,
                            lastSentPart: firstChunk,
                            timestamp: new Date().toISOString()
                        });
                        
                        const truncatedResponse = firstChunk + "\n\nüìù *Tape \"continue\" pour la suite...*";
                        addToMemory(senderIdStr, 'user', args);
                        addToMemory(senderIdStr, 'assistant', truncatedResponse);
                        log.info(`üîÑ Mistral avec troncature${searchResults ? ' (+ recherche int√©gr√©e)' : ''}`);
                        return truncatedResponse;
                    }
                }
                
                addToMemory(senderIdStr, 'user', args);
                addToMemory(senderIdStr, 'assistant', styledResponse);
                log.info(`üîÑ Mistral fallback${searchResults ? ' (+ recherche int√©gr√©e)' : ''}`);
                return styledResponse;
            }
            
            throw new Error('Mistral √©chec');
            
        } catch (mistralError) {
            log.error(`‚ùå Erreur totale: ${mistralError.message}`);
            
            const errorResponse = "ü§î J'ai rencontr√© une difficult√© technique. Peux-tu reformuler ? üí´";
            const styledError = parseMarkdown(errorResponse);
            addToMemory(senderIdStr, 'assistant', styledError);
            return styledError;
        }
    }
}

// ========================================
// ‚úâÔ∏è D√âTECTION CONTACT ADMIN
// ========================================

function detectContactAdminIntention(message) {
    const lowerMessage = message.toLowerCase();
    
    const patterns = [
        { patterns: [/(?:contacter|parler).*?(?:admin|durand)/i], reason: 'contact_direct' },
        { patterns: [/(?:probl√®me|bug|erreur).*?grave/i], reason: 'probleme_technique' },
        { patterns: [/(?:signaler|reporter)/i], reason: 'signalement' },
        { patterns: [/(?:suggestion|propose|id√©e)/i], reason: 'suggestion' },
        { patterns: [/(?:qui a cr√©√©|cr√©ateur)/i], reason: 'question_creation' },
        { patterns: [/(?:plainte|r√©clamation)/i], reason: 'plainte' }
    ];
    
    for (const category of patterns) {
        for (const pattern of category.patterns) {
            if (pattern.test(message)) {
                if (category.reason === 'question_creation') {
                    return { shouldContact: false };
                }
                return {
                    shouldContact: true,
                    reason: category.reason,
                    extractedMessage: message
                };
            }
        }
    }
    
    return { shouldContact: false };
}

function generateContactSuggestion(reason, extractedMessage) {
    const reasonMessages = {
        'contact_direct': { title: "üíå **Contact Admin**", message: "Tu veux contacter les administrateurs !" },
        'probleme_technique': { title: "üîß **Probl√®me Technique**", message: "Probl√®me technique d√©tect√© !" },
        'signalement': { title: "üö® **Signalement**", message: "Tu veux signaler quelque chose !" },
        'suggestion': { title: "üí° **Suggestion**", message: "Tu as une suggestion !" },
        'plainte': { title: "üìù **R√©clamation**", message: "Tu as une r√©clamation !" }
    };
    
    const reasonData = reasonMessages[reason] || {
        title: "üìû **Contact Admin**",
        message: "Tu as besoin de contacter les admins !"
    };
    
    const preview = extractedMessage.length > 60 ? extractedMessage.substring(0, 60) + "..." : extractedMessage;
    
    return `${reasonData.title}\n\n${reasonData.message}\n\nüí° Utilise \`/contact [ton message]\` pour les contacter.\n\nüìù Ton message: "${preview}"\n\n‚ö° Limite: 2 messages/jour\nüì® Tu recevras une r√©ponse !\n\nüíï En attendant, tape /help pour voir mes fonctionnalit√©s !`;
}

// ========================================
// ‚öôÔ∏è EX√âCUTION COMMANDE
// ========================================

async function executeCommandFromChat(senderId, commandName, args, ctx) {
    try {
        const COMMANDS = global.COMMANDS || new Map();
        
        if (!COMMANDS.has(commandName)) {
            const path = require('path');
            const fs = require('fs');
            const commandPath = path.join(__dirname, `${commandName}.js`);
            
            if (fs.existsSync(commandPath)) {
                delete require.cache[require.resolve(commandPath)];
                const commandModule = require(commandPath);
                
                if (typeof commandModule === 'function') {
                    const result = await commandModule(senderId, args, ctx);
                    return { success: true, result };
                }
            }
        } else {
            const commandFunction = COMMANDS.get(commandName);
            const result = await commandFunction(senderId, args, ctx);
            return { success: true, result };
        }
        
        return { success: false, error: `Commande ${commandName} non trouv√©e` };
        
    } catch (error) {
        return { success: false, error: error.message };
    }
}

async function generateContextualResponse(originalMessage, commandResult, commandName, ctx) {
    if (typeof commandResult === 'object' && commandResult.type === 'image') {
        return commandResult;
    }
    
    try {
        const contextPrompt = `Utilisateur: "${originalMessage}"
R√©sultat /${commandName}: "${commandResult}"

R√©ponds naturellement et amicalement (max 400 chars). Markdown simple OK, pas d'italique.`;

        const response = await callGeminiWithRotation(contextPrompt);
        return response || commandResult;
        
    } catch (error) {
        const { callMistralAPI } = ctx;
        try {
            const response = await callMistralAPI([
                { role: "system", content: "R√©ponds naturellement. Markdown simple OK." },
                { role: "user", content: `Utilisateur: "${originalMessage}"\nR√©sultat: "${commandResult}"\nPr√©sente naturellement (max 200 chars)` }
            ], 200, 0.7);
            
            return response || commandResult;
        } catch (mistralError) {
            return commandResult;
        }
    }
}

// ========================================
// üõ°Ô∏è FONCTION PRINCIPALE AVEC M√âMOIRE
// ========================================

module.exports = async function cmdChat(senderId, args, ctx) {
    const { addToMemory, getMemoryContext, callMistralAPI, log, 
            truncatedMessages, splitMessageIntoChunks, isContinuationRequest } = ctx;
    
    // Protection anti-doublons
    const messageSignature = `${senderId}_${args.trim().toLowerCase()}`;
    const currentTime = Date.now();
    
    if (recentMessages.has(messageSignature)) {
        const lastProcessed = recentMessages.get(messageSignature);
        if (currentTime - lastProcessed < 30000) {
            log.warning(`üö´ Message dupliqu√© ignor√© pour ${senderId}`);
            return;
        }
    }
    
    if (activeRequests.has(senderId)) {
        log.warning(`üö´ Demande en cours ignor√©e pour ${senderId}`);
        return;
    }
    
    // D√©lai de 5 secondes entre messages
    const lastMessageTime = Array.from(recentMessages.entries())
        .filter(([sig]) => sig.startsWith(`${senderId}_`))
        .map(([, timestamp]) => timestamp)
        .sort((a, b) => b - a)[0] || 0;
        
    if (lastMessageTime && (currentTime - lastMessageTime < 5000)) {
        const waitMessage = "üïí Veuillez patienter 5 secondes avant d'envoyer un nouveau message...";
        addToMemory(String(senderId), 'assistant', waitMessage);
        await ctx.sendMessage(senderId, waitMessage);
        return;
    }
    
    activeRequests.set(senderId, `${senderId}_${currentTime}`);
    recentMessages.set(messageSignature, currentTime);
    
    // Nettoyage cache ancien
    for (const [signature, timestamp] of recentMessages.entries()) {
        if (currentTime - timestamp > 120000) {
            recentMessages.delete(signature);
        }
    }
    
    try {
        // Message de traitement
        if (args.trim() && !isContinuationRequest(args)) {
            const processingMessage = "üïí Traitement en cours...";
            addToMemory(String(senderId), 'assistant', processingMessage);
            await ctx.sendMessage(senderId, processingMessage);
        }
        
        if (!args.trim()) {
            const welcomeMsg = "üí¨ Salut je suis NakamaBot! Je suis l√† pour toi ! Dis-moi ce qui t'int√©resse et on va avoir une conversation g√©niale ! ‚ú®";
            const styledWelcome = parseMarkdown(welcomeMsg);
            addToMemory(String(senderId), 'assistant', styledWelcome);
            return styledWelcome;
        }
        
        // üÜï R√âCUP√âRER L'HISTORIQUE COMPLET pour analyse contextuelle
        const conversationHistory = getMemoryContext(String(senderId)).slice(-10); // 10 derniers messages
        
        // Gestion continuation
        const senderIdStr = String(senderId);
        if (isContinuationRequest(args)) {
            const truncatedData = truncatedMessages.get(senderIdStr);
            if (truncatedData) {
                const { fullMessage, lastSentPart } = truncatedData;
                const lastSentIndex = fullMessage.indexOf(lastSentPart) + lastSentPart.length;
                const remainingMessage = fullMessage.substring(lastSentIndex);
                
                if (remainingMessage.trim()) {
                    const chunks = splitMessageIntoChunks(remainingMessage, 2000);
                    const nextChunk = parseMarkdown(chunks[0]);
                    
                    if (chunks.length > 1) {
                        truncatedMessages.set(senderIdStr, {
                            fullMessage,
                            lastSentPart: lastSentPart + chunks[0],
                            timestamp: new Date().toISOString()
                        });
                        
                        const continuationMsg = nextChunk + "\n\nüìù *Tape \"continue\" pour la suite...*";
                        addToMemory(senderIdStr, 'user', args);
                        addToMemory(senderIdStr, 'assistant', continuationMsg);
                        return continuationMsg;
                    } else {
                        truncatedMessages.delete(senderIdStr);
                        addToMemory(senderIdStr, 'user', args);
                        addToMemory(senderIdStr, 'assistant', nextChunk);
                        return nextChunk;
                    }
                } else {
                    truncatedMessages.delete(senderIdStr);
                    const endMsg = "‚úÖ C'est tout ! Y a-t-il autre chose que je puisse faire pour toi ? üí´";
                    addToMemory(senderIdStr, 'user', args);
                    addToMemory(senderIdStr, 'assistant', endMsg);
                    return endMsg;
                }
            } else {
                const noTruncMsg = "ü§î Il n'y a pas de message en cours √† continuer. Pose-moi une nouvelle question ! üí°";
                addToMemory(senderIdStr, 'user', args);
                addToMemory(senderIdStr, 'assistant', noTruncMsg);
                return noTruncMsg;
            }
        }
        
        // D√©tection contact admin
        const contactIntention = detectContactAdminIntention(args);
        if (contactIntention.shouldContact) {
            log.info(`üìû Intention contact admin: ${contactIntention.reason}`);
            const contactSuggestion = generateContactSuggestion(contactIntention.reason, contactIntention.extractedMessage);
            const styledContact = parseMarkdown(contactSuggestion);
            
            addToMemory(String(senderId), 'user', args);
            addToMemory(String(senderId), 'assistant', styledContact);
            return styledContact;
        }
        
        // üÜï D√âTECTION COMMANDES 100% IA avec historique
        const intelligentCommand = await detectIntelligentCommands(args, conversationHistory, ctx);
        if (intelligentCommand.shouldExecute) {
            log.info(`üß† Commande IA d√©tect√©e: /${intelligentCommand.command} (${intelligentCommand.confidence})`);
            
            try {
                const commandResult = await executeCommandFromChat(senderId, intelligentCommand.command, intelligentCommand.args, ctx);
                
                if (commandResult.success) {
                    if (typeof commandResult.result === 'object' && commandResult.result.type === 'image') {
                        addToMemory(String(senderId), 'user', args);
                        return commandResult.result;
                    }
                    
                    const contextualResponse = await generateContextualResponse(args, commandResult.result, intelligentCommand.command, ctx);
                    const styledResponse = parseMarkdown(contextualResponse);
                    
                    addToMemory(String(senderId), 'user', args);
                    addToMemory(String(senderId), 'assistant', styledResponse);
                    return styledResponse;
                }
            } catch (error) {
                log.error(`‚ùå Erreur commande IA: ${error.message}`);
            }
        }
        
        // üÜï D√âCISION RECHERCHE AVEC M√âMOIRE CONTEXTUELLE (en arri√®re-plan)
        const searchDecision = await decideSearchNecessity(args, senderId, conversationHistory, ctx);
        
        let searchResults = null;
        if (searchDecision.needsExternalSearch) {
            log.info(`üîç Recherche externe n√©cessaire: ${searchDecision.reason}`);
            if (searchDecision.usesConversationMemory) {
                log.info(`üß† Requ√™te enrichie avec m√©moire: "${searchDecision.searchQuery}"`);
            }
            
            try {
                // Lancer la recherche en parall√®le (ne bloque pas la conversation)
                searchResults = await performIntelligentSearch(searchDecision.searchQuery, ctx);
                
                if (searchResults && searchResults.length > 0) {
                    log.info(`üîç‚úÖ ${searchResults.length} r√©sultats trouv√©s - Int√©gration dans la conversation`);
                } else {
                    log.warning(`‚ö†Ô∏è Aucun r√©sultat trouv√© - Conversation normale`);
                    searchResults = null;
                }
            } catch (searchError) {
                log.error(`‚ùå Erreur recherche: ${searchError.message} - Continuation en conversation normale`);
                searchResults = null;
            }
        }
        
        // üÜï CONVERSATION UNIFI√âE: avec ou sans r√©sultats de recherche
        // La conversation continue naturellement, les r√©sultats sont juste inject√©s si disponibles
        return await handleConversationWithFallback(senderId, args, ctx, searchResults);
        
    } finally {
        activeRequests.delete(senderId);
        log.debug(`üîì Demande lib√©r√©e pour ${senderId}`);
    }
};

// ========================================
// üì§ EXPORTS
// ========================================

module.exports.detectIntelligentCommands = detectIntelligentCommands;
module.exports.VALID_COMMANDS = VALID_COMMANDS;
module.exports.executeCommandFromChat = executeCommandFromChat;
module.exports.detectContactAdminIntention = detectContactAdminIntention;
module.exports.decideSearchNecessity = decideSearchNecessity;
module.exports.performIntelligentSearch = performIntelligentSearch;
module.exports.generateNaturalResponseWithContext = generateNaturalResponseWithContext;
module.exports.analyzeConversationContext = analyzeConversationContext;
module.exports.callGeminiWithRotation = callGeminiWithRotation;
module.exports.getNextGeminiKey = getNextGeminiKey;
module.exports.markKeyAsFailed = markKeyAsFailed;
module.exports.parseMarkdown = parseMarkdown;
module.exports.toBold = toBold;
module.exports.toUnderline = toUnderline;
module.exports.toStrikethrough = toStrikethrough;
